{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9684ca1-c324-43bd-ad90-e74ddeb7063e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdb92300-cec9-4145-91e8-83e31dd6cf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "#To import modules\n",
    "sys.path.append('../')\n",
    "from notebooks.dataset_helper import DatasetHelper\n",
    "from codetector.src.features.shared.data.models.code_detection_sample_model import CodeDetectionSampleModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06a73db-63c1-448f-b77f-390b6a63fe4e",
   "metadata": {},
   "source": [
    "# Remove Later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecf5df4e-e533-4f6c-9718-5c70f4614f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from codetector.src.features.shared.data.models.dataset.parquet_dataset import ParquetDataset\n",
    "class TestDetectionParquetDataset(ParquetDataset):\n",
    "    def getContentType(self):\n",
    "        return CodeDetectionSampleModel\n",
    "\n",
    "    def preProcess(self):\n",
    "        pass\n",
    "\n",
    "    def getTag(self):\n",
    "        return 'test_detection_parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4be01a4-5e27-4921-ac8a-971e4b557b37",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cea1327c-0c92-4f11-88c0-0ea6fc9485be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset\n",
      "Converted to dataframe\n"
     ]
    }
   ],
   "source": [
    "parq = TestDetectionParquetDataset('../data/detection_parquet')\n",
    "parq.loadDataset()\n",
    "\n",
    "print('Loaded dataset')\n",
    "\n",
    "df = parq.toDataframe()\n",
    "\n",
    "\n",
    "print('Converted to dataframe')\n",
    "\n",
    "helper = DatasetHelper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d661826c",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7530510-b0d4-4918-bd64-3fb1d67b9429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(97308) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Calculating AUROC difference heat maps: 100%|█████████████████████████████████████████████████████████| 121/121 [01:30<00:00,  1.33it/s]\n",
      "Calculating AUROC difference heat maps: 100%|█████████████████████████████████████████████████████████| 121/121 [01:39<00:00,  1.22it/s]\n",
      "Calculating AUROC difference heat maps: 100%|█████████████████████████████████████████████████████████| 121/121 [01:23<00:00,  1.44it/s]\n",
      "Calculating AUROC difference heat maps: 100%|█████████████████████████████████████████████████████████| 121/121 [04:08<00:00,  2.05s/it]\n",
      "Calculating AUROC difference heat maps: 100%|█████████████████████████████████████████████████████████| 121/121 [01:13<00:00,  1.64it/s]\n"
     ]
    }
   ],
   "source": [
    "baseModels = ['codellama-13b',\n",
    "              'codellama-instruct-13b',\n",
    "              'llama3-8b',\n",
    "              'llama3-instruct-8b',\n",
    "              'codellama-7b',\n",
    "              'codellama-instruct-7b',\n",
    "              'codegen2_5-7b',\n",
    "              'codegeex2-6b',\n",
    "            #   'starcoder2-7b',\n",
    "              # 'codegemma-instruct-7b',\n",
    "              # 'wavecoderultra-7b',\n",
    "              'incoder-6b',\n",
    "              # 'phi3mini4k-instruct-4b',\n",
    "              # 'starcoder2-3b',\n",
    "              'phi-1b',\n",
    "              'incoder-1b',\n",
    "              ]\n",
    "# print(df.loc[(df['Dataset']=='hf_codesearchnet-python')&\n",
    "#                                              (((df['Temperature'] == 0.97)&(df['TopP'] == 0.95))|(df['Generator'] == 'human'))].head())\n",
    "\n",
    "# print(df.loc[(df['Dataset']=='hf_codesearchnet-python')]['Temperature'].value_counts())\n",
    "# print(df.loc[(df['Dataset']=='hf_codesearchnet-python')]['TopP'].value_counts())\n",
    "\n",
    "detectors = ['loglikelihood', 'entropy', 'rank', 'fastdetectgpt', 'binoculars']\n",
    "\n",
    "datasetPairs = [('stackoverflow-post', 'hf_codesearchnet-python', 'python', 'python_only'),\n",
    "                ('stackoverflow-post', 'hf_apps', 'python', 'python_only'),\n",
    "                ('stackoverflow-post', 'stackoverflow-pre', 'python', 'python_only'),\n",
    "                ('stackoverflow-post', 'stackoverflow-pre', None, 'all'),\n",
    "                ('leetcode-post', 'hf_leetcode-pre', None, 'all'),]\n",
    "\n",
    "\n",
    "for dataset1, dataset2, pl, folderPath in datasetPairs:\n",
    "  if pl:\n",
    "    auroc = helper.generateDifferenceHeatmap((parq,parq),\n",
    "                                            df=(df.loc[(df['Dataset']== dataset1) &(df['Language']==pl) & (((df['TopP']== 0.95) & (df['Temperature'] == 0.97)) | (df['Generator'] == 'human'))],\n",
    "                                                df.loc[(df['Dataset'] == dataset2) & (((df['TopP']== 0.95) & (df['Temperature'] == 0.97)) | (df['Generator'] == 'human')) &(df['Language']==pl)]),\n",
    "                                            flipList=['binoculars', 'detectcodegpt', 'rank'],\n",
    "                                            baseModels=baseModels,\n",
    "                                            generators=baseModels,\n",
    "                                            detectors=detectors,\n",
    "                                            folderPath=f'./figures/diff_heatmaps/analysis/{folderPath}',\n",
    "                                            suffix=f'_{dataset2}',\n",
    "                                            # diagonalDiff=True\n",
    "                                            )\n",
    "  else:\n",
    "    auroc = helper.generateDifferenceHeatmap((parq,parq),\n",
    "                                            df=(df.loc[(df['Dataset']== dataset1) & (((df['TopP']== 0.95) & (df['Temperature'] == 0.97)) | (df['Generator'] == 'human'))],\n",
    "                                                df.loc[(df['Dataset'] == dataset2) & (((df['TopP']== 0.95) & (df['Temperature'] == 0.97)) | (df['Generator'] == 'human'))]),\n",
    "                                            flipList=['binoculars', 'detectcodegpt', 'rank'],\n",
    "                                            baseModels=baseModels,\n",
    "                                            generators=baseModels,\n",
    "                                            detectors=detectors,\n",
    "                                            folderPath=f'./figures/diff_heatmaps/analysis/{folderPath}',\n",
    "                                            suffix=f'_{dataset2}',\n",
    "                                            # diagonalDiff=True\n",
    "                                            )\n",
    "# print(auroc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651b9d54-7303-4afc-a708-f79fdb08d168",
   "metadata": {},
   "source": [
    "## All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fff02f00-6a31-4e52-97aa-303dacfd9d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating AUROC difference heat maps: 100%|███████████████████████████████████████████████████████████████████| 272/272 [03:16<00:00,  1.38it/s]\n",
      "Calculating AUROC difference heat maps: 100%|███████████████████████████████████████████████████████████████████| 272/272 [03:35<00:00,  1.26it/s]\n",
      "Calculating AUROC difference heat maps: 100%|███████████████████████████████████████████████████████████████████| 256/256 [02:54<00:00,  1.47it/s]\n",
      "Calculating AUROC difference heat maps: 100%|███████████████████████████████████████████████████████████████████| 256/256 [08:38<00:00,  2.03s/it]\n",
      "Calculating AUROC difference heat maps: 100%|███████████████████████████████████████████████████████████████████| 272/272 [02:44<00:00,  1.65it/s]\n"
     ]
    }
   ],
   "source": [
    "baseModels = ['codellama-13b',\n",
    "              'codellama-instruct-13b',\n",
    "              'llama3-8b',\n",
    "              'llama3-instruct-8b',\n",
    "              'codellama-7b',\n",
    "              'codellama-instruct-7b',\n",
    "              'codegen2_5-7b',\n",
    "              'codegeex2-6b',\n",
    "              'starcoder2-7b',\n",
    "              'codegemma-instruct-7b',\n",
    "              'wavecoderultra-7b',\n",
    "              'incoder-6b',\n",
    "              'phi3mini4k-instruct-4b',\n",
    "              'starcoder2-3b',\n",
    "              'phi-1b',\n",
    "              'incoder-1b',\n",
    "              ]\n",
    "\n",
    "detectors = ['loglikelihood', 'entropy', 'rank', 'fastdetectgpt', 'binoculars']\n",
    "\n",
    "datasetPairs = [('stackoverflow-post', 'hf_codesearchnet-python', 'python', 'python_only'),\n",
    "                ('stackoverflow-post', 'hf_apps', 'python', 'python_only'),\n",
    "                ('stackoverflow-post', 'stackoverflow-pre', 'python', 'python_only'),\n",
    "                ('stackoverflow-post', 'stackoverflow-pre', None, 'all'),\n",
    "                ('leetcode-post', 'hf_leetcode-pre', None, 'all'),]\n",
    "\n",
    "\n",
    "for dataset1, dataset2, pl, folderPath in datasetPairs:\n",
    "  if pl:\n",
    "    auroc = helper.generateDifferenceHeatmap((parq,parq),\n",
    "                                            df=(df.loc[(df['Dataset']== dataset1) &(df['Language']==pl) & (((df['TopP']== 0.95) & (df['Temperature'] == 0.97)) | (df['Generator'] == 'human'))],\n",
    "                                                df.loc[(df['Dataset'] == dataset2) & (((df['TopP']== 0.95) & (df['Temperature'] == 0.97)) | (df['Generator'] == 'human')) &(df['Language']==pl)]),\n",
    "                                            flipList=['binoculars', 'detectcodegpt', 'rank'],\n",
    "                                            baseModels=baseModels,\n",
    "                                            generators=baseModels + (['openaio1-mini'] if dataset2 != 'stackoverflow-pre' else []),\n",
    "                                            detectors=detectors,\n",
    "                                            folderPath=f'./figures/diff_heatmaps/all/{folderPath}',\n",
    "                                            suffix=f'_{dataset2}'\n",
    "                                            )\n",
    "  else:\n",
    "    auroc = helper.generateDifferenceHeatmap((parq,parq),\n",
    "                                            df=(df.loc[(df['Dataset']== dataset1) & (((df['TopP']== 0.95) & (df['Temperature'] == 0.97)) | (df['Generator'] == 'human'))],\n",
    "                                                df.loc[(df['Dataset'] == dataset2) & (((df['TopP']== 0.95) & (df['Temperature'] == 0.97)) | (df['Generator'] == 'human'))]),\n",
    "                                            flipList=['binoculars', 'detectcodegpt', 'rank'],\n",
    "                                            baseModels=baseModels,\n",
    "                                            generators=baseModels + (['openaio1-mini'] if dataset2 != 'stackoverflow-pre' else []),\n",
    "                                            detectors=detectors,\n",
    "                                            folderPath=f'./figures/diff_heatmaps/all/{folderPath}',\n",
    "                                            suffix=f'_{dataset2}'\n",
    "                                            )\n",
    "# print(auroc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16c4a19",
   "metadata": {},
   "source": [
    "## Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905e026c",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8842979b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating AUROC difference heat maps: 100%|█████████████████████████████████████████████████████████| 121/121 [01:27<00:00,  1.38it/s]\n",
      "Calculating AUROC difference heat maps: 100%|█████████████████████████████████████████████████████████| 121/121 [01:27<00:00,  1.39it/s]\n",
      "Calculating AUROC difference heat maps: 100%|█████████████████████████████████████████████████████████| 121/121 [01:28<00:00,  1.37it/s]\n"
     ]
    }
   ],
   "source": [
    "baseModels = ['codellama-13b',\n",
    "              'codellama-instruct-13b',\n",
    "              'llama3-8b',\n",
    "              'llama3-instruct-8b',\n",
    "              'codellama-7b',\n",
    "              'codellama-instruct-7b',\n",
    "              'codegen2_5-7b',\n",
    "              'codegeex2-6b',\n",
    "            #   'starcoder2-7b',\n",
    "              # 'codegemma-instruct-7b',\n",
    "              # 'wavecoderultra-7b',\n",
    "              'incoder-6b',\n",
    "              # 'phi3mini4k-instruct-4b',\n",
    "              # 'starcoder2-3b',\n",
    "              'phi-1b',\n",
    "              'incoder-1b',\n",
    "              ]\n",
    "\n",
    "\n",
    "detectors = ['loglikelihood', 'entropy', 'rank', 'fastdetectgpt', 'binoculars']\n",
    "\n",
    "ps = [0.95,0.5]\n",
    "temps = [0.97,0.2]\n",
    "\n",
    "\n",
    "for temperature in temps:\n",
    "  for p in ps:\n",
    "    if p==0.95 and temperature == 0.97:\n",
    "          continue\n",
    "    auroc = helper.generateDifferenceHeatmap((parq,parq),\n",
    "                                            df=(df.loc[(df['Dataset']== 'hf_codesearchnet-python') & (((df['TopP']== p) & (df['Temperature'] == temperature)) | (df['Generator'] == 'human'))],\n",
    "                                                df.loc[(df['Dataset'] == 'hf_codesearchnet-python') & (((df['TopP']== 0.95) & (df['Temperature'] == 0.97)) | (df['Generator'] == 'human'))]),\n",
    "                                            flipList=['binoculars', 'detectcodegpt', 'rank'],\n",
    "                                            baseModels=baseModels,\n",
    "                                            generators=baseModels,\n",
    "                                            detectors=detectors,\n",
    "                                            folderPath=f'./figures/diff_heatmaps/diff_temp_top_p/analysis',\n",
    "                                            suffix=f'_{temperature}_{p}'\n",
    "                                            )\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c40721a",
   "metadata": {},
   "source": [
    "### All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab9585c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating AUROC difference heat maps: 100%|███████████████████████████████████████████████████████████████████| 256/256 [02:59<00:00,  1.43it/s]\n",
      "Calculating AUROC difference heat maps: 100%|██████████████████████████████████████████████| 256/256 [03:02<00:00,  1.40it/s]\n",
      "Calculating AUROC difference heat maps: 100%|██████████████████████████████████████████████| 256/256 [03:00<00:00,  1.42it/s]\n"
     ]
    }
   ],
   "source": [
    "baseModels = ['codellama-13b',\n",
    "              'codellama-instruct-13b',\n",
    "              'llama3-8b',\n",
    "              'llama3-instruct-8b',\n",
    "              'codellama-7b',\n",
    "              'codellama-instruct-7b',\n",
    "              'codegen2_5-7b',\n",
    "              'codegeex2-6b',\n",
    "              'starcoder2-7b',\n",
    "              'codegemma-instruct-7b',\n",
    "              'wavecoderultra-7b',\n",
    "              'incoder-6b',\n",
    "              'phi3mini4k-instruct-4b',\n",
    "              'starcoder2-3b',\n",
    "              'phi-1b',\n",
    "              'incoder-1b',\n",
    "              ]\n",
    "\n",
    "detectors = ['loglikelihood', 'entropy', 'rank', 'fastdetectgpt', 'binoculars']\n",
    "\n",
    "ps = [0.95,0.5]\n",
    "temps = [0.97,0.2]\n",
    "\n",
    "\n",
    "for temperature in temps:\n",
    "  for p in ps:\n",
    "    if p==0.95 and temperature == 0.97:\n",
    "          continue\n",
    "    auroc = helper.generateDifferenceHeatmap((parq,parq),\n",
    "                                            df=(df.loc[(df['Dataset']== 'hf_codesearchnet-python') & (((df['TopP']== p) & (df['Temperature'] == temperature)) | (df['Generator'] == 'human'))],\n",
    "                                                df.loc[(df['Dataset'] == 'hf_codesearchnet-python') & (((df['TopP']== 0.95) & (df['Temperature'] == 0.97)) | (df['Generator'] == 'human'))]),\n",
    "                                            flipList=['binoculars', 'detectcodegpt', 'rank'],\n",
    "                                            baseModels=baseModels,\n",
    "                                            generators=baseModels,\n",
    "                                            detectors=detectors,\n",
    "                                            folderPath=f'./figures/diff_heatmaps/diff_temp_top_p/all',\n",
    "                                            suffix=f'_{temperature}_{p}'\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942d66e9",
   "metadata": {},
   "source": [
    "## Programming Language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b031dbaa",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a99636a-9575-4c3a-aac6-e829424b852e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating AUROC difference heat maps: 100%|█████████████████████████████████████████████████████████| 121/121 [04:48<00:00,  2.38s/it]\n",
      "Calculating AUROC difference heat maps: 100%|█████████████████████████████████████████████████████████| 121/121 [04:13<00:00,  2.09s/it]\n",
      "Calculating AUROC difference heat maps: 100%|█████████████████████████████████████████████████████████| 121/121 [04:06<00:00,  2.04s/it]\n",
      "Calculating AUROC difference heat maps: 100%|█████████████████████████████████████████████████████████| 121/121 [04:22<00:00,  2.17s/it]\n",
      "Calculating AUROC difference heat maps: 100%|█████████████████████████████████████████████████████████| 121/121 [03:38<00:00,  1.80s/it]\n",
      "Calculating AUROC difference heat maps: 100%|█████████████████████████████████████████████████████████| 121/121 [03:36<00:00,  1.79s/it]\n",
      "Calculating AUROC difference heat maps:  83%|███████████████████████████████████████████████          | 100/121 [03:55<00:49,  2.35s/it]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'codellama-13b'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m        plPairs\u001b[38;5;241m.\u001b[39mappend((pl,pl2))\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pl1, pl2 \u001b[38;5;129;01min\u001b[39;00m plPairs:\n\u001b[0;32m---> 34\u001b[0m     auroc \u001b[38;5;241m=\u001b[39m \u001b[43mhelper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerateDifferenceHeatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparq\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLanguage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43mpl1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTopP\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTemperature\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.97\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGenerator\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhuman\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTopP\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTemperature\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.97\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGenerator\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhuman\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLanguage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43mpl2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mflipList\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbinoculars\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdetectcodegpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrank\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mbaseModels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaseModels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mgenerators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaseModels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdetectors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetectors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mfolderPath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./figures/diff_heatmaps/languages/analysis\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpl1\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpl2\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/RWTH/AI Paper/code/codetector/notebooks/../notebooks/dataset_helper.py:385\u001b[0m, in \u001b[0;36mDatasetHelper.generateDifferenceHeatmap\u001b[0;34m(self, datasets, df, generators, baseModels, detectors, folderPath, suffix, flipList, diagonalDiff)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m detector \u001b[38;5;129;01min\u001b[39;00m auroc\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m baseModel \u001b[38;5;129;01min\u001b[39;00m auroc[detector]:\n\u001b[0;32m--> 385\u001b[0m         data[detector][generatorIndex,baseModelIndex] \u001b[38;5;241m=\u001b[39m \u001b[43maurocComparison\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdetector\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbaseModel\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m-\u001b[39m auroc[detector][baseModel]\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m(detector \u001b[38;5;129;01min\u001b[39;00m aurocToReturn):\n\u001b[1;32m    388\u001b[0m             aurocToReturn[detector] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomparison\u001b[39m\u001b[38;5;124m'\u001b[39m:[], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauroc\u001b[39m\u001b[38;5;124m'\u001b[39m:[]}\n",
      "\u001b[0;31mKeyError\u001b[0m: 'codellama-13b'"
     ]
    }
   ],
   "source": [
    "baseModels = ['codellama-13b',\n",
    "              'codellama-instruct-13b',\n",
    "              'llama3-8b',\n",
    "              'llama3-instruct-8b',\n",
    "              'codellama-7b',\n",
    "              'codellama-instruct-7b',\n",
    "              'codegen2_5-7b',\n",
    "              'codegeex2-6b',\n",
    "            #   'starcoder2-7b',\n",
    "              # 'codegemma-instruct-7b',\n",
    "              # 'wavecoderultra-7b',\n",
    "              'incoder-6b',\n",
    "              # 'phi3mini4k-instruct-4b',\n",
    "              # 'starcoder2-3b',\n",
    "              'phi-1b',\n",
    "              'incoder-1b',\n",
    "              ]\n",
    "\n",
    "\n",
    "detectors = ['loglikelihood', 'entropy', 'rank', 'fastdetectgpt', 'binoculars']\n",
    "\n",
    "\n",
    "pls = ['python','java','js','csharp','cpp','go','rust']\n",
    "\n",
    "plPairs = []\n",
    "\n",
    "for pl in pls:\n",
    "  for pl2 in pls:\n",
    "    if pl != pl2:\n",
    "       plPairs.append((pl,pl2))\n",
    "\n",
    "\n",
    "for pl1, pl2 in plPairs:\n",
    "    auroc = helper.generateDifferenceHeatmap((parq,parq),\n",
    "                                            df=(df.loc[(df['Language']==pl1) & (((df['TopP']== 0.95) & (df['Temperature'] == 0.97)) | (df['Generator'] == 'human'))],\n",
    "                                                df.loc[(((df['TopP']== 0.95) & (df['Temperature'] == 0.97)) | (df['Generator'] == 'human')) &(df['Language']==pl2)]),\n",
    "                                            flipList=['binoculars', 'detectcodegpt', 'rank'],\n",
    "                                            baseModels=baseModels,\n",
    "                                            generators=baseModels,\n",
    "                                            detectors=detectors,\n",
    "                                            folderPath=f'./figures/diff_heatmaps/languages/analysis',\n",
    "                                            suffix=f'_{pl1}_{pl2}'\n",
    "                                            )\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9382a64d",
   "metadata": {},
   "source": [
    "### All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000c53b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseModels = ['codellama-13b',\n",
    "              'codellama-instruct-13b',\n",
    "              'llama3-8b',\n",
    "              'llama3-instruct-8b',\n",
    "              'codellama-7b',\n",
    "              'codellama-instruct-7b',\n",
    "              'codegen2_5-7b',\n",
    "              'codegeex2-6b',\n",
    "              'starcoder2-7b',\n",
    "              'codegemma-instruct-7b',\n",
    "              'wavecoderultra-7b',\n",
    "              'incoder-6b',\n",
    "              'phi3mini4k-instruct-4b',\n",
    "              'starcoder2-3b',\n",
    "              'phi-1b',\n",
    "              'incoder-1b',\n",
    "              ]\n",
    "\n",
    "\n",
    "detectors = ['loglikelihood', 'entropy', 'rank', 'fastdetectgpt', 'binoculars']\n",
    "\n",
    "\n",
    "pls = ['python','java','js','csharp','cpp','go','rust']\n",
    "\n",
    "plPairs = []\n",
    "\n",
    "for pl in pls:\n",
    "  for pl2 in pls:\n",
    "    if pl != pl2:\n",
    "       plPairs.append((pl,pl2))\n",
    "\n",
    "\n",
    "for pl1, pl2 in plPairs:\n",
    "    auroc = helper.generateDifferenceHeatmap((parq,parq),\n",
    "                                            df=(df.loc[(df['Language']==pl1) & (((df['TopP']== 0.95) & (df['Temperature'] == 0.97)) | (df['Generator'] == 'human'))],\n",
    "                                                df.loc[(((df['TopP']== 0.95) & (df['Temperature'] == 0.97)) | (df['Generator'] == 'human')) &(df['Language']==pl2)]),\n",
    "                                            flipList=['binoculars', 'detectcodegpt', 'rank'],\n",
    "                                            baseModels=baseModels,\n",
    "                                            generators=baseModels+['openaio1-mini'],\n",
    "                                            detectors=detectors,\n",
    "                                            folderPath=f'./figures/diff_heatmaps/languages/all',\n",
    "                                            suffix=f'_{pl1}_{pl2}'\n",
    "                                            )\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d22e13-3a86-465b-9f74-d6db3192ba67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
