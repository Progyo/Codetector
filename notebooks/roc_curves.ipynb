{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9684ca1-c324-43bd-ad90-e74ddeb7063e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdb92300-cec9-4145-91e8-83e31dd6cf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "#To import modules\n",
    "sys.path.append('../')\n",
    "from notebooks.dataset_helper import DatasetHelper\n",
    "from codetector.src.features.shared.data.models.code_detection_sample_model import CodeDetectionSampleModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06a73db-63c1-448f-b77f-390b6a63fe4e",
   "metadata": {},
   "source": [
    "# Remove Later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecf5df4e-e533-4f6c-9718-5c70f4614f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from codetector.src.features.shared.data.models.dataset.parquet_dataset import ParquetDataset\n",
    "class TestDetectionParquetDataset(ParquetDataset):\n",
    "    def getContentType(self):\n",
    "        return CodeDetectionSampleModel\n",
    "\n",
    "    def preProcess(self):\n",
    "        pass\n",
    "\n",
    "    def getTag(self):\n",
    "        return 'test_detection_parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4be01a4-5e27-4921-ac8a-971e4b557b37",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cea1327c-0c92-4f11-88c0-0ea6fc9485be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset\n",
      "Converted to dataframe\n"
     ]
    }
   ],
   "source": [
    "parq = TestDetectionParquetDataset('../data/detection_parquet')\n",
    "parq.loadDataset()\n",
    "\n",
    "print('Loaded dataset')\n",
    "\n",
    "df = parq.toDataframe()\n",
    "\n",
    "\n",
    "print('Converted to dataframe')\n",
    "\n",
    "helper = DatasetHelper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c73e867-7285-4799-8fd7-f8f376c88ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseModels = ['codellama-13b',\n",
    "              'codellama-instruct-13b',\n",
    "              'llama3-8b',\n",
    "              'llama3-instruct-8b',\n",
    "              'codellama-7b',\n",
    "              'codellama-instruct-7b',\n",
    "              'codegen2_5-7b',\n",
    "              'codegeex2-6b',\n",
    "              'starcoder2-7b',\n",
    "              'codegemma-instruct-7b',\n",
    "              'wavecoderultra-7b',\n",
    "              'incoder-6b',\n",
    "              'phi3mini4k-instruct-4b',\n",
    "              'starcoder2-3b',\n",
    "              'phi-1b',\n",
    "              'incoder-1b',\n",
    "             ] \n",
    "\n",
    "generators = baseModels + ['openaio1-mini']\n",
    "\n",
    "detectors = ['loglikelihood', 'entropy', 'rank', 'fastdetectgpt', 'binoculars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e08af095-ba1f-4b31-a083-2fe1635191de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating hf_codesearchnet-python:   0%|                                                                                                      | 0/3 [00:00<?, ?it/s]\n",
      "Looping through generators:   0%|                                                                                                               | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Looping through base models:   0%|                                                                                                              | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Looping through base models: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                                                                                      \u001b[A\u001b[A\n",
      "Looping through generators: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.46s/it]\u001b[A\n",
      "Calculating hf_apps:  33%|████████████████████████████████████▋                                                                         | 1/3 [00:01<00:02,  1.46s/it]\u001b[A\n",
      "Looping through generators:   0%|                                                                                                               | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Looping through base models:   0%|                                                                                                              | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Looping through base models: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                                                                                      \u001b[A\u001b[A\n",
      "Looping through generators: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.55s/it]\u001b[A\n",
      "Calculating stackoverflow-post:  67%|██████████████████████████████████████████████████████████████████                                 | 2/3 [00:03<00:01,  1.51s/it]\u001b[A\n",
      "Looping through generators:   0%|                                                                                                               | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Looping through base models:   0%|                                                                                                              | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Looping through base models: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                                                                                      \u001b[A\u001b[A\n",
      "Looping through generators: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.46s/it]\u001b[A\n",
      "Calculating stackoverflow-post: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.49s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done calculating AUROC!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Looping through detectors:   0%|                                                                                                                | 0/1 [00:00<?, ?it/s]\n",
      "Looping through generators:   0%|                                                                                                               | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Looping through base models:   0%|                                                                                                              | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Looping through datasets:   0%|                                                                                                                 | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                                                                                                      \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Looping through base models: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                                                                                      \u001b[A\u001b[A\n",
      "Looping through generators: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.03it/s]\u001b[A\n",
      "Looping through detectors: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.85it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "### All squares\n",
    "datasets = ['hf_codesearchnet-python', 'hf_apps', 'stackoverflow-post']\n",
    "bar = tqdm(datasets,position=0)\n",
    "auroc_vals : dict[str,dict] = {}\n",
    "\n",
    "for dataset in bar:\n",
    "    tag = dataset\n",
    "    bar.set_description(f'Calculating {tag}')\n",
    "    \n",
    "    auroc_vals[tag] = {}\n",
    "    for detector in detectors:\n",
    "        auroc_vals[tag][detector] = {}\n",
    "\n",
    "    for generator in tqdm(generators,position=1,desc='Looping through generators',leave=False):\n",
    "        genTag = generator\n",
    "        for detector in detectors:\n",
    "            auroc_vals[tag][detector][genTag] = {}\n",
    "        \n",
    "        for baseModel in tqdm(baseModels, position=2, desc='Looping through base models',leave=False):\n",
    "            baseTag = baseModel\n",
    "            filtered = df.loc[(df['Dataset'] == tag) & (df['Language'] == 'python') & ((df['TopP'] == 0.95) & (df['Temperature'] == 0.97)  | (df['Generator'] == 'human'))]\n",
    "            temp = helper.calculateAUROCScores(parq,filtered,sameGeneratorOnly=False, baseModelOverride=baseTag,generatorOverride=genTag, flipList=['binoculars', 'detectcodegpt', 'rank'], returnFprTpr=True)\n",
    "            for detector in temp:\n",
    "                if not (detector in detectors):\n",
    "                    continue\n",
    "                \n",
    "                if detector in temp and baseTag in temp[detector]:\n",
    "                    auroc_vals[tag][detector][genTag][baseTag] =  temp[detector][baseTag]\n",
    "        #         break\n",
    "        #     break\n",
    "        # break\n",
    "\n",
    "print('Done calculating AUROC!')\n",
    "\n",
    "detectors = list(list(auroc_vals.values())[0].keys())#list(map(lambda x:x.keys(),auroc_vals.values()))\n",
    "\n",
    "for detector in tqdm(detectors, desc='Looping through detectors', position=0):\n",
    "    generators = list(list(auroc_vals.values())[0][detector].keys())\n",
    "    # print(generators)\n",
    "    for generator in tqdm(generators, desc='Looping through generators', position=1,leave=False):\n",
    "        baseModels = list(list(auroc_vals.values())[0][detector][generator].keys())\n",
    "        # print(baseModels)\n",
    "        for baseModel in tqdm(baseModels, desc='Looping through base models', position=2, leave=False):\n",
    "            # print(f'{detector}, BM: {baseModel}')\n",
    "            for dataset in tqdm(auroc_vals, desc='Looping through datasets', position=3,leave=False):\n",
    "                # if not(generator in auroc_vals[dataset][detector]) or not(baseModel in auroc_vals[dataset][detector][generator]):\n",
    "                #     continue\n",
    "                auroc, fpr, tpr, _ = auroc_vals[dataset][detector][generator][baseModel]\n",
    "        \n",
    "                plt.plot(fpr,tpr,label=f'{dataset}, AUC: {round(auroc,4)}')\n",
    "            plt.title(f'{detector.capitalize()} (Python Only)\\nBase: {baseModel}\\nGen: {generator}') #\n",
    "\n",
    "            plt.xlabel(\"False Positive Rate\")\n",
    "            plt.ylabel(\"True Positive Rate\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "            # plt.rcParams['legend.loc'] = 'lower right'\n",
    "            plt.legend()\n",
    "            # plt.show()\n",
    "            plt.rcParams['svg.fonttype'] = 'none'\n",
    "            \n",
    "            plt.savefig(f'./figures/roc/{detector}/{baseModel}_{generator}.png')\n",
    "            plt.savefig(f'./figures/roc/{detector}/{baseModel}_{generator}.svg')\n",
    "            # plt.clf()\n",
    "            plt.close()\n",
    "            # exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163dc3de-43b9-467c-b5c6-b5c24bd3eede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
